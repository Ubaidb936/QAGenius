{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e415ef-cbc5-4538-aeb1-ed011c0d0692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "WARNING! repo_id is not default parameter.\n",
      "                    repo_id was transferred to model_kwargs.\n",
      "                    Please confirm that repo_id is what you intended.\n",
      "WARNING! task is not default parameter.\n",
      "                    task was transferred to model_kwargs.\n",
      "                    Please confirm that task is what you intended.\n",
      "WARNING! huggingfacehub_api_token is not default parameter.\n",
      "                    huggingfacehub_api_token was transferred to model_kwargs.\n",
      "                    Please confirm that huggingfacehub_api_token is what you intended.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import config \n",
    "import shutil\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import config\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "import json\n",
    "import datasets\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.chat_models import ChatHuggingFace\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "pdfPath = config.pdfPath\n",
    "hf_token = config.hf_token\n",
    "model_id = config.model_id\n",
    "title = config.title\n",
    "file_path = config.file_path\n",
    "##ensuring the config.py variables are set\n",
    "if pdfPath is None:\n",
    "    raise ValueError(\"pdfPath is None. Please set the  pdf path in config.py.\")\n",
    "\n",
    "if hf_token is None:\n",
    "    raise ValueError(\"hf_token is None. Please set the huggingFace token in config.py.\")\n",
    "\n",
    "if model_id is None:\n",
    "    raise ValueError(\"model_id is None. Please set the model_id in config.py.\")\n",
    "\n",
    "if title is None:\n",
    "    raise ValueError(\"title is None. Please set the title of the Pdf in config.py.\")\n",
    "\n",
    "if file_path is None:\n",
    "    raise ValueError(\"file_path is None. Please set the local file_path in config.py.\")\n",
    "\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = hf_token\n",
    "\n",
    "\n",
    "# model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "# model_id = \"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\"\n",
    "\n",
    "#loading the hugginFace LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id= model_id,\n",
    "    task=\"text-generation\",\n",
    "    # huggingfacehub_api_token = hf_token,\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_k\": 30,\n",
    "        \"temperature\": 0.1,\n",
    "        \"repetition_penalty\": 1.03,\n",
    "    },\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm, token = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89d44b-bfc6-4876-95fa-f4cc24ab4b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b48aa0-68de-49cb-9916-a27bc3d5a420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c46b6e-4730-4f26-add1-636215160b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775979b-c9e8-46b4-ad8d-c179d8ad933f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "912bf6fd-a533-4020-9647-7d5d459c9d71",
   "metadata": {},
   "source": [
    "                                             Walking through a Single Data Point Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5beff-a88d-468e-8099-9ff9ecf87c62",
   "metadata": {},
   "source": [
    "1- Loading a Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f08ca6e-5988-429b-8c83-573527b023aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(pdfPath) #I am Loading Pdf Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9cc163-6925-43ac-ad34-faa2818ebec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646badd-c278-450b-aa23-d89af9bdd300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758487a-50d4-4d7d-871b-4c831841777e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abbccce4-2a39-4e18-8038-d75b94aa0734",
   "metadata": {},
   "source": [
    "2- Splitting the Text File Into Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28f8b3f8-8710-4832-ab05-c75540edfc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=2000,  \n",
    "        chunk_overlap=200,\n",
    "        add_start_index=True,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "    )\n",
    "try:\n",
    "    langchain_docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbe500c9-8e97-48c2-a792-56deeb9a6ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Splits are : 2\n"
     ]
    }
   ],
   "source": [
    "#Logging the Number of the Splits Generated from the Text File Uploaded...\n",
    "print(f\"Number of Splits are : {len(langchain_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3a999-3052-4560-87fd-9b09143f34aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc4f2a-068d-48cb-ae2c-ec6cada7b2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b50e35-ae7c-460e-921e-b9ef3fd9909a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd215f58-6912-49de-8010-9b87914b66b4",
   "metadata": {},
   "source": [
    "3- Splits: Each Split will serve as a context to the LLM for Developing Question and Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f769ff71-fc17-492b-9146-2004dc70338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case: The People vs. Smith Witness: John Doe Date: February 23, 2024 Location: City Courthouse Direct Examination by Prosecution: Prosecutor: Mr. Doe, could you please state your name and occupation for the record? John Doe: Yes, my name is John Doe, and I am a neighbor of the defendant, Mr. Smith. I work as a software engineer at a local tech company. Prosecutor: Thank you, Mr. Doe. Now, could you describe for the court any interactions you've had with the defendant, Mr. Smith, in the past? John Doe: Certainly. I've lived next door to Mr. Smith for the past five years, and we've had several interactions during that time. He's always been cordial and polite whenever we've crossed paths. Prosecutor: Have you ever witnessed any concerning behavior from Mr. Smith during your time as his neighbor? John Doe: Yes, there was one incident about six months ago that caught my attention. I heard loud noises coming from Mr. Smith's house late at night, and when I looked out my window, I saw him arguing with someone on his front porch. It sounded quite heated, and I was concerned about the disturbance. Prosecutor: Did you see anyone else involved in the argument besides Mr. Smith? John Doe: No, I couldn't see the other person clearly from my vantage point, but I could hear their voices raised in argument. Prosecutor: Thank you, Mr. Doe. Can you provide more details about the argument? What specifically did you hear? John Doe: Well, it's hard to recall the exact words, but I remember phrases like \"I can't believe you would do this\" and \"this is unacceptable.\" It was definitely a heated exchange. Prosecutor: Did you witness any physical altercations or violence during this incident? John Doe: No, I did not see any physical altercations. Prosecutor: How would you characterize your relationship with Mr. Smith prior to this incident?\n"
     ]
    }
   ],
   "source": [
    "#Selecting a Random Split which serves as a context for developing QNA\n",
    "split = random.choice(langchain_docs)\n",
    "context = split\n",
    "context.page_content = context.page_content.replace('\\n', ' ')\n",
    "print(context.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a1544-5d47-48cf-b01f-65179b679727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e51994-6a8e-4c22-b5b1-a0ab433cb099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea27ea-2070-4784-9f33-bb1a39de1d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13786f9d-6222-446d-a50d-19f5c798b9a7",
   "metadata": {},
   "source": [
    "4- Question Answer Generation LLM Agent (Agent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d10bd5-dfb0-433b-b670-c518e433a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Case: The People vs. Smith Witness: John Doe Date: February 23, 2024 Location: City Courthouse Direct Examination by Prosecution: Prosecutor: Mr. Doe, could you please state your name and occupation for the record? John Doe: Yes, my name is John Doe, and I am a neighbor of the defendant, Mr. Smith. I work as a software engineer at a local tech company. Prosecutor: Thank you, Mr. Doe. Now, could you describe for the court any interactions you've had with the defendant, Mr. Smith, in the past? John Doe: Certainly. I've lived next door to Mr. Smith for the past five years, and we've had several interactions during that time. He's always been cordial and polite whenever we've crossed paths. Prosecutor: Have you ever witnessed any concerning behavior from Mr. Smith during your time as his neighbor? John Doe: Yes, there was one incident about six months ago that caught my attention. I heard loud noises coming from Mr. Smith's house late at night, and when I looked out my window, I saw him arguing with someone on his front porch. It sounded quite heated, and I was concerned about the disturbance. Prosecutor: Did you see anyone else involved in the argument besides Mr. Smith? John Doe: No, I couldn't see the other person clearly from my vantage point, but I could hear their voices raised in argument. Prosecutor: Thank you, Mr. Doe. Can you provide more details about the argument? What specifically did you hear? John Doe: Well, it's hard to recall the exact words, but I remember phrases like \"I can't believe you would do this\" and \"this is unacceptable.\" It was definitely a heated exchange. Prosecutor: Did you witness any physical altercations or violence during this incident? John Doe: No, I did not see any physical altercations. Prosecutor: How would you characterize your relationship with Mr. Smith prior to this incident?\n",
      "\n",
      "\n",
      "question Generated : What is the occupation of the witness, John Doe?\n",
      "\n",
      "answer Generated : John Doe works as a software engineer at a local tech company.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "QA_generation_prompt = \"\"\"\n",
    "Your task is to develop factoid questions and  answers from  a given context.\n",
    "Your factoid question should be answerable with a specific, concise piece of factual information from the context.\n",
    "Your factoid question should be formulated in the same style as questions users could ask in a search engine.\n",
    "This means that your factoid question MUST NOT mention something like \"according to the passage\" or \"context\".\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Output:::\n",
    "Factoid question: (your factoid question)\n",
    "Answer: (your answer to the factoid question)\n",
    "\n",
    "\n",
    "\n",
    "Now here is the context.\n",
    "\n",
    "Context: {context}\\n\n",
    "Output:::\"\"\"\n",
    "\n",
    "QA_generation_prompt = ChatPromptTemplate.from_template(QA_generation_prompt)\n",
    "QA_generation_agent = QA_generation_prompt | chat_model\n",
    "output_QA_couple = QA_generation_agent.invoke({\"context\": context.page_content}).content\n",
    "# print(\"Output from the LLM to the INPUT prompt-----------------\")\n",
    "# print(output_QA_couple)\n",
    "question = output_QA_couple.split(\"Factoid question: \")[2].split(\"Answer: \")[0]\n",
    "answer = output_QA_couple.split(\"Answer: \")[2]\n",
    "index = answer.find(\"Factoid question:\")\n",
    "answer = answer[:index].strip()\n",
    "datapoint = { \"context\": context.page_content,\n",
    "             \"question\": question,\n",
    "             \"answer\": answer,\n",
    "             \"source_doc\": context.metadata[\"source\"],\n",
    "            }\n",
    "# print(output_QA_couple)\n",
    "print(f\"Context: {context.page_content}\\n\\n\")\n",
    "print(f\"question Generated : {question}\")\n",
    "print(f\"answer Generated : {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca5b76-6653-491d-8503-ffcdc6b91583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c47279-c947-409a-88d2-15a683baa8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da49393-70d9-406d-a388-90cbb390bda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50e16ba5-7f50-4c44-bf1f-f4fb642be53c",
   "metadata": {},
   "source": [
    "5- groundedness Score Generation LLM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3be88766-7285-439a-9f60-b464e8e43e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Case: The People vs. Smith Witness: John Doe Date: February 23, 2024 Location: City Courthouse Direct Examination by Prosecution: Prosecutor: Mr. Doe, could you please state your name and occupation for the record? John Doe: Yes, my name is John Doe, and I am a neighbor of the defendant, Mr. Smith. I work as a software engineer at a local tech company. Prosecutor: Thank you, Mr. Doe. Now, could you describe for the court any interactions you've had with the defendant, Mr. Smith, in the past? John Doe: Certainly. I've lived next door to Mr. Smith for the past five years, and we've had several interactions during that time. He's always been cordial and polite whenever we've crossed paths. Prosecutor: Have you ever witnessed any concerning behavior from Mr. Smith during your time as his neighbor? John Doe: Yes, there was one incident about six months ago that caught my attention. I heard loud noises coming from Mr. Smith's house late at night, and when I looked out my window, I saw him arguing with someone on his front porch. It sounded quite heated, and I was concerned about the disturbance. Prosecutor: Did you see anyone else involved in the argument besides Mr. Smith? John Doe: No, I couldn't see the other person clearly from my vantage point, but I could hear their voices raised in argument. Prosecutor: Thank you, Mr. Doe. Can you provide more details about the argument? What specifically did you hear? John Doe: Well, it's hard to recall the exact words, but I remember phrases like \"I can't believe you would do this\" and \"this is unacceptable.\" It was definitely a heated exchange. Prosecutor: Did you witness any physical altercations or violence during this incident? John Doe: No, I did not see any physical altercations. Prosecutor: How would you characterize your relationship with Mr. Smith prior to this incident?\n",
      "\n",
      "\n",
      "question: What is the occupation of the witness, John Doe?\n",
      "\n",
      "\n",
      "\n",
      "groundedness_score: 5\n",
      "groundedness_eval: The context directly states John Doe's occupation, providing a clear and unambiguous answer to the question.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_groundedness_critique_prompt = \"\"\"\n",
    "You will be given a context and a question.\n",
    "\n",
    "Your task is to provide a 'total rating' scoring how well one can answer the given question unambiguously with the \n",
    "given context.\n",
    "\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question is not answerable at all given the context, \n",
    "and 5 means that the question is clearly and unambiguously answerable with the context.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating)\n",
    "Total rating: (your rating)\n",
    "\n",
    "Now here are the question and context.\n",
    "\n",
    "Question: {question}\\n\n",
    "Context: {context}\\n\n",
    "Answer::: \"\"\"\n",
    "\n",
    "question_groundedness_critique_prompt = ChatPromptTemplate.from_template(\n",
    "    question_groundedness_critique_prompt\n",
    ")\n",
    "question_groundedness_critique_agent = question_groundedness_critique_prompt | chat_model\n",
    "\n",
    "# Critique the generated QA couple\n",
    "question_groundedness_evaluation = question_groundedness_critique_agent.invoke(\n",
    "    {\"context\": context.page_content, \"question\": question}\n",
    ").content\n",
    "##Extracting the Evaluation and Evaluation Score, this can cause error \n",
    "groundedness_score = int(question_groundedness_evaluation.split(\"Total rating: \")[2][0])\n",
    "groundedness_eval = question_groundedness_evaluation.split(\"Total rating: \")[1].split(\"Evaluation: \")[1]\n",
    "datapoint.update(\n",
    "            {\n",
    "                \"groundedness_score\": groundedness_score,\n",
    "                \"groundedness_eval\": groundedness_eval,\n",
    "            }\n",
    "        )\n",
    "# print(question_groundedness_evaluation)\n",
    "print(f\"Context: {context.page_content}\\n\\n\")\n",
    "print(f\"question: {question}\\n\\n\")\n",
    "print(f\"groundedness_score: {groundedness_score}\")\n",
    "print(f\"groundedness_eval: {groundedness_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7fe69-8b87-4fce-bd07-3da2fe95cb11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be7d38-318f-4154-8292-fa007b26f239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811fb2d-cbf8-4149-9f70-5b1647c227e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c1d13b0-0325-4e4e-8ac9-2c8616170dc6",
   "metadata": {},
   "source": [
    "6 - Relevance Score Generation LLM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c2bead5-3828-4663-82ee-2a6d6bf62289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: What is the occupation of the witness, John Doe?\n",
      "\n",
      "relevance_score: 4\n",
      "relevance_eval : The occupation of a witness can be relevant to their credibility and potential biases. For example, a witness who is a lawyer or a police officer may be perceived as having a greater level of expertise or knowledge about legal proceedings, while a witness who stands to gain or lose financially from the outcome of a case may have a motivation to lie or distort the truth. Additionally, the occupation of a witness can also provide context for their observations and interactions with other individuals involved in the case. Therefore, this question has the potential to be useful in evaluating the testimony of John Doe.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step 6----------\n",
    "question_relevance_critique_prompt = \"\"\"\n",
    "You will be given a question.\n",
    "Your task is to provide a 'total rating' representing how useful this question can be to  {title}\\n\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question is not useful at all, and 5 means that the question is extremely useful.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating)\n",
    "Total rating: (your rating)\n",
    "\n",
    "Now here is the question.\n",
    "\n",
    "Question: {question}\\n\n",
    "Answer::: \"\"\"\n",
    "question_relevance_critique_prompt = ChatPromptTemplate.from_template(\n",
    "    question_relevance_critique_prompt\n",
    ")\n",
    "question_relevance_critique_agent = question_relevance_critique_prompt | chat_model\n",
    "\n",
    "\n",
    "\n",
    "question_relevance_evaluation = question_relevance_critique_agent.invoke(\n",
    "        {\"title\": title, \"question\": question}\n",
    "    ).content\n",
    "\n",
    "\n",
    "#extracting the relevance_score and eval\n",
    "relevance_score = int(question_relevance_evaluation.split(\"Total rating: \")[2][0])\n",
    "relevance_eval = question_relevance_evaluation.split(\"Total rating: \")[1].split(\"Evaluation: \")[1]\n",
    "datapoint.update(\n",
    "            {\n",
    "\n",
    "                \"relevance_score\": relevance_score,\n",
    "                \"relevance_eval\": relevance_eval,\n",
    "            }\n",
    "        )\n",
    "print(f\"question: {question}\")\n",
    "print(f\"relevance_score: {relevance_score}\")\n",
    "print(f\"relevance_eval : {relevance_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc9690-97ad-4574-9a86-971e264b779d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9674b-f81d-4f3f-b719-26d6f100dab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb1351-4616-457c-983d-c03408f3abf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdc336dc-c5c1-4dce-a2e1-cca3d718d837",
   "metadata": {},
   "source": [
    "7- Displaying dataPoint Generated......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00449779-acdd-4ebe-9b51-d2135ad936ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source_doc</th>\n",
       "      <th>groundedness_score</th>\n",
       "      <th>groundedness_eval</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>relevance_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case: The People vs. Smith Witness: John Doe D...</td>\n",
       "      <td>What is the occupation of the witness, John Do...</td>\n",
       "      <td>John Doe works as a software engineer at a loc...</td>\n",
       "      <td>Testimony101.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>The context directly states John Doe's occupat...</td>\n",
       "      <td>4</td>\n",
       "      <td>The occupation of a witness can be relevant to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Case: The People vs. Smith Witness: John Doe D...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What is the occupation of the witness, John Do...   \n",
       "\n",
       "                                              answer        source_doc  \\\n",
       "0  John Doe works as a software engineer at a loc...  Testimony101.pdf   \n",
       "\n",
       "   groundedness_score                                  groundedness_eval  \\\n",
       "0                   5  The context directly states John Doe's occupat...   \n",
       "\n",
       "   relevance_score                                     relevance_eval  \n",
       "0                4  The occupation of a witness can be relevant to...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ls = [datapoint]\n",
    "df = pd.DataFrame(ls)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e1afd03-f2a5-47c8-a878-75a3b8c81b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2df1ab4a4e485b8073a65a9f82f689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ec166a0a7540b49a24b415108d479e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0329c319c8b848eda76726fe9c9afe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/555 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Ubaidbhat/QAGeniusPresentation/commit/3041804edf2af317311d017e172d664b8bb8a320', commit_message='Upload dataset', commit_description='', oid='3041804edf2af317311d017e172d664b8bb8a320', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save Locally\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset.push_to_hub(\"QAGeniusPresentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302b155-4a33-49cd-8c64-4ed57b2c79d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
